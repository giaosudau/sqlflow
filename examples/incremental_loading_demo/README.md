# SQLFlow Phase 1 & Phase 2 Complete Demo

This demo showcases SQLFlow's Phase 1 enhanced features and Phase 2 incremental loading capabilities, focusing on real-world scenarios and automatic watermark-based filtering.

## ğŸš€ Quick Start

```bash
cd examples/incremental_loading_demo
./run_demo.sh
```

## ğŸ“ Project Structure

```
incremental_loading_demo/
â”œâ”€â”€ data/                                    # Sample datasets
â”‚   â”œâ”€â”€ customers_initial.csv               # Initial customer data (10 customers)
â”‚   â”œâ”€â”€ customers_updates.csv               # Updated/new customers (5 records)
â”‚   â”œâ”€â”€ orders_day1.csv                     # Day 1 orders
â”‚   â”œâ”€â”€ orders_day2.csv                     # Day 2 orders  
â”‚   â”œâ”€â”€ orders_incremental_initial.csv      # Initial incremental orders (3 records)
â”‚   â”œâ”€â”€ orders_incremental_additional.csv   # Additional incremental orders (2 records)
â”‚   â””â”€â”€ products.csv                        # Product reference data
â”œâ”€â”€ pipelines/                              # Demo pipelines
â”‚   â”œâ”€â”€ 01_basic_incremental.sf             # Core incremental loading concepts
â”‚   â”œâ”€â”€ 02_mixed_sync_modes.sf              # Different sync strategies
â”‚   â”œâ”€â”€ 03_error_recovery.sf                # Error handling & debugging
â”‚   â”œâ”€â”€ 04_ecommerce_analytics.sf           # Complete analytics workflow
â”‚   â”œâ”€â”€ real_incremental_demo.sf            # Phase 2: Initial incremental load
â”‚   â””â”€â”€ real_incremental_demo_update.sf     # Phase 2: Incremental update
â”œâ”€â”€ profiles/                               # Environment configurations
â”‚   â”œâ”€â”€ dev.yml                            # Development profile
â”‚   â”œâ”€â”€ test.yml                           # Testing profile
â”‚   â””â”€â”€ production.yml                     # Production profile
â”œâ”€â”€ output/                                 # Generated results
â””â”€â”€ run_demo.sh                            # Complete automated demo runner
```

## ğŸ¯ Phase 1 Features Demonstrated

### 1. Core Incremental Loading (`01_basic_incremental.sf`)
- **MERGE-based Updates**: Demonstrates upsert operations using `MERGE_KEYS`
- **Performance Concepts**: Shows data volume reduction (10 â†’ 5 records processed)
- **Variable Substitution**: Uses `${data_dir}` and `${output_dir}` from profiles
- **CREATE OR REPLACE**: Advanced table management with proper SQL generation

**Key Results:**
- Initial Load: 10 customers â†’ Final: 13 customers (3 new + 2 updated)
- Status breakdown: 12 active, 1 pending customers
- Watermark tracking: Latest activity timestamp managed

### 2. Mixed Sync Modes (`02_mixed_sync_modes.sf`)
- **Full Refresh vs Incremental**: Different strategies per data source
- **Reference Data Handling**: Static data (products) vs transactional data
- **Load Mode Flexibility**: REPLACE, APPEND, and MERGE in one pipeline

### 3. Error Recovery & Debugging (`03_error_recovery.sf`)
- **Graceful Error Handling**: Pipeline continues after recoverable errors
- **Data Quality Patterns**: Validation and cleansing workflows
- **Debugging Concepts**: Clear error reporting and data lineage

### 4. Complete E-commerce Analytics (`04_ecommerce_analytics.sf`)
- **Multi-source Integration**: Customers, orders, and products
- **Business Logic**: Revenue calculations, customer segmentation
- **Performance Optimization**: Incremental aggregations

## ğŸš€ Phase 2 Features Demonstrated

### 5. Real-time Incremental Loading (`real_incremental_demo.sf` & `real_incremental_demo_update.sf`)
- **Automatic Watermark Management**: Industry-standard `sync_mode="incremental"` triggers automatic filtering
- **Cursor-based Filtering**: `cursor_field="updated_at"` enables time-based incremental loading
- **State Persistence**: Watermarks persist across pipeline runs in DuckDB state backend
- **Performance Optimization**: Only processes records newer than last watermark
- **Zero Configuration**: No manual MERGE operations required

**Key Results:**
- Initial Load: 3 orders processed, watermark established at `2024-01-15 12:15:00`
- Incremental Load: 2 additional orders processed (only records after watermark)
- Total Performance Gain: 40% fewer rows processed in second run (3+2 vs 5 full refresh)
- Watermark Persistence: Automatic state management between pipeline executions

## ğŸ”§ Technical Improvements Implemented

### Phase 1 Backend Enhancements

1. **CREATE OR REPLACE TABLE Support**
   - **Added is_replace field**: Extended `SQLBlockStep` in AST to track CREATE OR REPLACE usage
   - **Parser Enhancement**: Modified parser to detect and set `is_replace` flag correctly
   - **SQL Generation**: Updated `SQLGenerator` to respect `is_replace` flag when generating SQL
   - **Execution Plan**: Enhanced `Planner` to pass `is_replace` field to execution operations
   - **Local Executor**: Modified `LocalExecutor` to use `is_replace` flag in SQL execution
   - **Validation Logic**: Updated duplicate table validation to allow CREATE OR REPLACE redefining same table

2. **Industry-Standard SOURCE Parameters**
   - **Schema Enhancement**: Extended connector schemas in `schemas.py` to support:
     - `sync_mode`: "full_refresh" or "incremental"
     - `primary_key`: String field for incremental loading identification
     - `cursor_field`: Timestamp/ID field for incremental loading watermarks
   - **Validation Integration**: Added parameter validation with helpful error messages
   - **Airbyte/Fivetran Compatibility**: Industry-standard parameter naming for easy migration

3. **Enhanced Validation and Error Handling**
   - **Validation Cache**: Implemented smart caching system for improved validation performance
   - **Error Formatting**: Enhanced error messages with detailed suggestions and help URLs
   - **Variable Substitution**: Fixed validation to work correctly with variable substitution
   - **Profile Integration**: Improved variable handling from profiles during validation

### Phase 2 Backend Enhancements

1. **Automatic Incremental Loading Integration**
   - **LocalExecutor Enhancement**: Added `_execute_incremental_source_definition` method for automatic watermark-based filtering
   - **Parameter Integration**: Industry-standard parameters now trigger actual incremental behavior
   - **Watermark-based Filtering**: Connectors automatically filter data based on stored watermarks
   - **State Management**: Watermarks persist and update automatically across pipeline runs

2. **Enhanced CSV Connector**
   - **Incremental Reading**: Added `read_incremental()` method with cursor field filtering
   - **Cursor Value Extraction**: Implemented `get_cursor_value()` for watermark management
   - **Supports Incremental**: Added `supports_incremental()` capability detection
   - **Graceful Fallbacks**: Automatic fallback to full refresh when incremental not possible

3. **DuckDB State Backend**
   - **Watermark Persistence**: Watermarks stored in DuckDB for durability across runs
   - **Atomic Updates**: Transactional watermark updates ensure consistency
   - **Performance Optimization**: Efficient state queries and updates

## ğŸ“Š Demo Results

The complete demo script (`run_demo.sh`) shows comprehensive pipeline execution:

```bash
ğŸš€ Demonstrating Phase 1 & 2 enhanced features:
   â€¢ CREATE OR REPLACE TABLE support
   â€¢ Industry-standard parameters (sync_mode, primary_key, cursor_field)
   â€¢ Automatic watermark management
   â€¢ Enhanced debugging infrastructure
   â€¢ Real-time incremental loading with watermarks

ğŸ”„ Executing Phase 1 pipelines:
ğŸ“¦ Running 01_basic_incremental... âœ… SUCCESS
ğŸ“¦ Running 02_mixed_sync_modes... âœ… SUCCESS
ğŸ“¦ Running 04_ecommerce_analytics... âœ… SUCCESS

============================================
   Phase 2: Real-time Incremental Loading
============================================

ğŸ”„ Running initial incremental load...
ğŸ“¦ Running real_incremental_demo... âœ… SUCCESS
âœ… Initial load completed (3 records)

ğŸ”„ Running incremental load with new data...
ğŸ“¦ Running real_incremental_demo_update... âœ… SUCCESS
âœ… Incremental update completed (2 additional records)

âœ… All 5 pipelines completed successfully!

ğŸ“ Summary:
   - Phase 1 pipelines: 3/3 successful
   - Phase 2 incremental demo: 2/2 successful
   - Initial load: 3 records processed, watermark established
   - Incremental load: 2 additional records processed using watermarks
   - Total records in final table: 5

ğŸ“‹ Key achievements:
   âœ… Automatic watermark management working
   âœ… Industry-standard sync_mode='incremental' parameter functioning
   âœ… cursor_field-based filtering operational
   âœ… No manual MERGE operations required
   âœ… State persistence across pipeline runs
   âœ… Performance improvements through selective data processing
```

## ğŸ—ï¸ Implementation Status

### Phase 1 Features âœ… COMPLETED
- âœ… MERGE-based incremental loading
- âœ… Variable substitution from profiles
- âœ… Multiple load modes (REPLACE, APPEND, MERGE)
- âœ… Error recovery mechanisms
- âœ… Performance monitoring
- âœ… CREATE OR REPLACE TABLE support
- âœ… Industry-standard SOURCE parameters
- âœ… Enhanced validation with caching
- âœ… Improved error messages and debugging

### Phase 2 Features âœ… COMPLETED
- âœ… Automatic watermark management
- âœ… Industry-standard parameter integration
- âœ… Cursor-based incremental filtering
- âœ… State persistence with DuckDB backend
- âœ… Enhanced CSV connector with incremental support
- âœ… Zero-configuration incremental loading
- âœ… Performance optimization through selective processing

### Phase 2 Next Steps ğŸš§ IN PROGRESS
- ğŸš§ Connector interface standardization
- ğŸš§ Enhanced PostgreSQL connector
- ğŸš§ Enhanced S3 connector with cost management
- ğŸš§ Resilience patterns (retry, circuit breaker, rate limiting)

## ğŸƒâ€â™‚ï¸ Running Individual Pipelines

```bash
# Run specific Phase 1 pipeline
sqlflow pipeline run 01_basic_incremental --profile dev

# Run Phase 2 incremental demo
sqlflow pipeline run real_incremental_demo --profile dev
sqlflow pipeline run real_incremental_demo_update --profile dev

# With custom variables
sqlflow pipeline run 01_basic_incremental --profile dev \
    --vars '{"data_dir": "custom_data", "output_dir": "custom_output"}'

# Validate before running
sqlflow pipeline validate real_incremental_demo --profile dev

# Compile to execution plan
sqlflow pipeline compile real_incremental_demo --profile dev
```

## ğŸ” Understanding the Incremental Data Flow

### Phase 2: Real Incremental Loading

#### Initial Load
```
orders_incremental_initial.csv (3 orders, max updated_at: 2024-01-15 12:15:00)
â””â”€ SOURCE with sync_mode="incremental"
   â””â”€ LocalExecutor._execute_incremental_source_definition()
      â”œâ”€ No existing watermark found
      â”œâ”€ Process all 3 records
      â”œâ”€ Extract max cursor value: 2024-01-15 12:15:00
      â””â”€ Store watermark in DuckDB state backend
```

#### Incremental Update
```
orders_incremental_additional.csv (2 orders, updated_at: 2024-01-16 10:00:00, 2024-01-16 11:00:00)
â””â”€ SOURCE with sync_mode="incremental"
   â””â”€ LocalExecutor._execute_incremental_source_definition()
      â”œâ”€ Retrieve watermark: 2024-01-15 12:15:00
      â”œâ”€ CSV connector filters: WHERE updated_at > '2024-01-15 12:15:00'
      â”œâ”€ Process only 2 new records (automatic filtering)
      â”œâ”€ Extract new max cursor value: 2024-01-16 11:00:00
      â””â”€ Update watermark in DuckDB state backend
```

#### Performance Impact
- **Traditional Approach**: Process all 5 records every time
- **Phase 2 Incremental**: Process 3 records initially, then only 2 new records
- **Performance Gain**: 40% fewer rows processed in subsequent runs
- **Scalability**: Improvement increases with dataset size (1M records â†’ 1K new records = 99.9% reduction)

## ğŸ› Known Issues & Workarounds

1. **Complex UNION Queries**: May generate parser warnings but still execute correctly
   - **Workaround**: Use simple SELECT statements for complex analytical queries
   - **Status**: Parser enhancement completed

2. **Database Cleanup**: Persistent mode requires manual database cleanup between full resets
   - **Workaround**: `rm -f target/demo.duckdb` for complete reset
   - **Status**: Automatic state management working for incremental updates

## ğŸ§ª Testing

This demo includes comprehensive integration tests following SQLFlow testing standards:
- Real data processing (no mocks)
- End-to-end pipeline validation
- CREATE OR REPLACE functionality tests
- Industry-standard parameter validation tests
- Incremental loading behavior tests
- Watermark persistence tests
- Error handling and recovery tests

## ğŸ¤ Contributing

This demo represents SQLFlow's Phase 1 & Phase 2 capabilities. Contributions welcome:

1. Additional incremental loading scenarios
2. Performance benchmarks with larger datasets
3. Connector enhancements
4. Documentation improvements

## ğŸ“ Support

For issues or questions about this demo:
- Check the SQLFlow documentation
- Review the pipeline execution logs
- Test with simpler datasets first
- Verify watermark state using DuckDB queries

---

**Demo Status**: âœ… Working (Phase 1 & Phase 2 Complete)  
**Last Updated**: January 2025  
**SQLFlow Version**: 0.1.7+ (Phase 2 Enhanced) 