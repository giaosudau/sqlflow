-- Nested Conditions Pipeline Example
-- This example demonstrates using nested conditional blocks to handle
-- complex decision trees based on multiple variables

-- Define data sources
SOURCE postgres_source (
    connector_type = "POSTGRES",
    host = "${db_host|localhost}",
    port = "${db_port|5432}",
    database = "${db_name|app_db}",
    username = "${db_user|postgres}",
    password = "${db_password}",
    schema = "${db_schema|public}"
);

SOURCE s3_source (
    connector_type = "S3",
    bucket = "${data_bucket|example-data}",
    region = "${aws_region|us-east-1}",
    access_key = "${aws_access_key}",
    secret_key = "${aws_secret_key}"
);

-- Complex nested conditional logic based on environment and region
IF ${env} == 'production' THEN
    -- Production environment has different data sources per region
    IF ${region} == 'us-east' THEN
        -- US East region uses a specific production database
        LOAD customers FROM SOURCE postgres_source
        WITH (
            query = "SELECT * FROM customers WHERE region = 'us-east'"
        );
        
        -- Apply region-specific transformations
        CREATE TABLE transformed_customers AS
        SELECT
            id,
            name,
            email,
            'US-East' as region,
            timezone,
            created_at
        FROM customers
        WHERE status = 'active';
        
    ELSE IF ${region} == 'us-west' THEN
        -- US West region uses another production database
        LOAD customers FROM SOURCE postgres_source
        WITH (
            query = "SELECT * FROM customers WHERE region = 'us-west'"
        );
        
        -- Apply region-specific transformations
        CREATE TABLE transformed_customers AS
        SELECT
            id,
            name,
            email,
            'US-West' as region,
            timezone,
            created_at
        FROM customers
        WHERE status = 'active';
        
    ELSE IF ${region} == 'eu' THEN
        -- EU region has additional compliance requirements
        LOAD customers FROM SOURCE postgres_source
        WITH (
            query = "SELECT * FROM customers WHERE region = 'eu'"
        );
        
        -- Apply EU-specific transformations with GDPR considerations
        CREATE TABLE eu_consent AS
        SELECT
            customer_id,
            MAX(consent_date) as latest_consent_date,
            bool_and(marketing_consent) as has_marketing_consent
        FROM customer_consents
        GROUP BY customer_id;
        
        CREATE TABLE transformed_customers AS
        SELECT
            c.id,
            c.name,
            -- Only include email if marketing consent given
            CASE WHEN e.has_marketing_consent THEN c.email ELSE NULL END as email,
            'EU' as region,
            c.timezone,
            c.created_at
        FROM customers c
        LEFT JOIN eu_consent e ON c.id = e.customer_id
        WHERE c.status = 'active';
        
    ELSE
        -- Default region handling for production
        LOAD customers FROM SOURCE postgres_source
        WITH (
            query = "SELECT * FROM customers WHERE region NOT IN ('us-east', 'us-west', 'eu')"
        );
        
        CREATE TABLE transformed_customers AS
        SELECT
            id,
            name,
            email,
            'Other' as region,
            timezone,
            created_at
        FROM customers
        WHERE status = 'active';
        
    END IF;
    
    -- Additional production-specific processing across all regions
    CREATE TABLE customer_metrics AS
    SELECT
        region,
        COUNT(*) as customer_count,
        COUNT(DISTINCT email) as unique_emails
    FROM transformed_customers
    GROUP BY region;
    
ELSE IF ${env} == 'staging' THEN
    -- Staging environment has simplified region handling
    IF ${use_production_data|false} == true THEN
        -- Option to use production data in staging for testing
        LOAD customers FROM SOURCE postgres_source
        WITH (
            query = "SELECT * FROM customers WHERE created_at > CURRENT_DATE - INTERVAL '7 days'"
        );
    ELSE
        -- Otherwise use staging data
        LOAD customers FROM SOURCE postgres_source
        WITH (
            query = "SELECT * FROM staging.customers LIMIT 1000"
        );
    END IF;
    
    -- Apply staging transformations
    CREATE TABLE transformed_customers AS
    SELECT
        id,
        name,
        email,
        region,
        timezone,
        created_at
    FROM customers;
    
    -- Simplified metrics for staging
    CREATE TABLE customer_metrics AS
    SELECT
        COUNT(*) as customer_count
    FROM transformed_customers;
    
ELSE
    -- Development environment
    IF ${use_sample_data|true} == true THEN
        -- Use sample data from S3
        LOAD customers FROM SOURCE s3_source
        WITH (
            path = "sample_data/customers.csv",
            format = "csv",
            header = "true"
        );
    ELSE
        -- Use local development database
        LOAD customers FROM SOURCE postgres_source
        WITH (
            query = "SELECT * FROM dev.customers LIMIT 100"
        );
    END IF;
    
    -- Simple pass-through for development
    CREATE TABLE transformed_customers AS
    SELECT * FROM customers;
    
    -- Development metrics are minimal
    CREATE TABLE customer_metrics AS
    SELECT
        COUNT(*) as customer_count
    FROM transformed_customers;
END IF;

-- Final export varies by environment but not nested
IF ${env} == 'production' THEN
    -- Production exports to data warehouse
    EXPORT TO bigquery_destination
    FROM customer_metrics
    WITH (
        project = "my-production-project",
        dataset = "analytics",
        table = "customer_metrics",
        create_disposition = "CREATE_IF_NEEDED",
        write_disposition = "WRITE_TRUNCATE"
    );
ELSE
    -- Non-production exports to local files
    EXPORT TO file_destination
    FROM customer_metrics
    WITH (
        path = "./output/${env}/customer_metrics.json",
        format = "json"
    );
END IF; 