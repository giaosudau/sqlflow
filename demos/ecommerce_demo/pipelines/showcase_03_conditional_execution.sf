-- ===============================================================
-- SHOWCASE CONDITIONAL: Demonstrates conditional execution in SQLFlow
-- ===============================================================
-- Run with: docker compose exec sqlflow sqlflow pipeline run /app/sqlflow/demos/ecommerce_demo/pipelines/showcase_03_conditional_execution.sf --vars '{"environment": "production", "region": "us-east"}'

-- Define dynamic variables with defaults
SET environment = "${environment|development}";
SET region = "${region|all}";
SET date = "${date|2023-10-25}";
SET output_dir = "target";

-- ===============================================================
-- PART 1: SETUP DATA SOURCES
-- ===============================================================

-- Load data based on environment
SOURCE sales TYPE CSV PARAMS {
  -- In production, we use the full dataset
  "path": CASE 
    WHEN "${environment}" = "production" THEN "data/sales.csv"
    -- In development, we use a smaller dataset
    ELSE "data/sales_2023-10-25.csv"
  END,
  "has_header": true
};

SOURCE customers TYPE CSV PARAMS {
  "path": "data/customers.csv",
  "has_header": true
};

SOURCE products TYPE CSV PARAMS {
  "path": "data/products.csv",
  "has_header": true
};

-- Load data into in-memory tables
LOAD sales_table FROM sales;
LOAD customers_table FROM customers;
LOAD products_table FROM products;

-- ===============================================================
-- PART 2: ENVIRONMENT-BASED PROCESSING
-- ===============================================================

-- Create joined dataset with filtering based on environment
CREATE TABLE sales_enriched AS 
SELECT
  s.order_id,
  s.customer_id,
  c.name AS customer_name,
  c.region,
  s.product_id,
  p.name AS product_name,
  p.category,
  CAST(s.quantity AS INTEGER) AS quantity,
  CAST(s.price AS DOUBLE) AS price,
  (CAST(s.quantity AS INTEGER) * CAST(s.price AS DOUBLE)) AS total_amount,
  s.order_date
FROM sales_table s
JOIN customers_table c ON s.customer_id = c.customer_id
JOIN products_table p ON s.product_id = p.product_id
-- For development, limit to recent data
WHERE CASE 
  WHEN "${environment}" = "development" THEN 
    -- In development, use smaller dataset
    1=1 
  WHEN "${environment}" = "staging" THEN 
    -- In staging, use last 90 days
    s.order_date >= '2023-07-28'
  ELSE 
    -- In production, use full dataset
    1=1
END;

-- ===============================================================
-- PART 3: REGION-BASED FILTERING
-- ===============================================================

-- Filter data by region if specified
CREATE TABLE region_filtered_sales AS
SELECT *
FROM sales_enriched
WHERE CASE
  WHEN "${region}" = "all" THEN 1=1
  ELSE region = "${region}"
END;

-- ===============================================================
-- PART 4: CONDITIONAL AGGREGATIONS
-- ===============================================================

-- Run different analytics based on environment and region
CREATE TABLE sales_summary AS
SELECT
  -- Include environment and region in output
  '${environment}' AS environment,
  CASE WHEN "${region}" = "all" THEN "All Regions" ELSE "${region}" END AS region,
  COUNT(DISTINCT order_id) AS total_orders,
  COUNT(DISTINCT customer_id) AS total_customers,
  SUM(quantity) AS total_items_sold,
  SUM(total_amount) AS total_revenue,
  -- In production, calculate more detailed metrics
  CASE WHEN "${environment}" = "production" THEN
    AVG(total_amount)
  ELSE
    0.0
  END AS avg_order_value
FROM region_filtered_sales;

-- Create detailed summaries only in production
IF "${environment}" = "production" THEN
  -- Product category analysis for production reports
  CREATE TABLE category_summary AS
  SELECT
    category,
    COUNT(DISTINCT order_id) AS orders,
    SUM(quantity) AS units_sold,
    SUM(total_amount) AS revenue,
    AVG(total_amount) AS avg_order_value
  FROM region_filtered_sales
  GROUP BY category
  ORDER BY revenue DESC;
  
  -- Export the detailed category summary
  EXPORT SELECT * FROM category_summary
  TO "${output_dir}/category_summary_${environment}_${region}_${date}.csv"
  TYPE CSV
  OPTIONS { 
    "header": true
  };
END IF;

-- ===============================================================
-- PART 5: ENVIRONMENT-SPECIFIC EXPORTS
-- ===============================================================

-- Basic summary export for all environments
EXPORT SELECT * FROM sales_summary
TO "${output_dir}/sales_summary_${environment}_${region}_${date}.csv"
TYPE CSV
OPTIONS { 
  "header": true
};

-- Production-only exports
IF "${environment}" = "production" THEN
  -- 1. Additional detailed export to S3
  EXPORT SELECT * FROM sales_summary
  TO "s3://analytics/reports/sales_summary_${environment}_${region}_${date}.parquet"
  TYPE S3
  OPTIONS { 
    "format": "parquet",
    "compression": "snappy",
    "endpoint_url": "http://minio:9000",
    "region": "us-east-1",
    "access_key": "minioadmin",
    "secret_key": "minioadmin",
    "bucket": "analytics"
  };
  
  -- 2. Send notification to API 
  EXPORT SELECT 
    '${date}' AS report_date,
    '${environment}' AS environment,
    '${region}' AS region,
    (SELECT total_orders FROM sales_summary) AS total_orders,
    (SELECT total_revenue FROM sales_summary) AS total_revenue
  TO "http://mockserver:1080/api/reports/production-notification"
  TYPE REST
  OPTIONS {
    "method": "POST",
    "headers": {
      "Content-Type": "application/json",
      "Authorization": "Bearer production-token"
    }
  };
ELSE IF "${environment}" = "staging" THEN
  -- Staging-specific notification
  EXPORT SELECT 
    '${date}' AS report_date,
    '${environment}' AS environment,
    '${region}' AS region,
    (SELECT total_orders FROM sales_summary) AS total_orders
  TO "http://mockserver:1080/api/reports/staging-notification"
  TYPE REST
  OPTIONS {
    "method": "POST",
    "headers": {
      "Content-Type": "application/json",
      "Authorization": "Bearer staging-token"
    }
  };
END IF;
END IF;

-- ===============================================================
-- PART 6: AUDIT LOGGING (ALL ENVIRONMENTS)
-- ===============================================================

-- Create and export audit log entry for all environments
CREATE TABLE execution_audit_log AS
SELECT
  '${environment}' AS environment,
  '${region}' AS region,
  '${date}' AS report_date,
  CURRENT_TIMESTAMP() AS execution_time,
  (SELECT COUNT(*) FROM sales_table) AS source_rows,
  (SELECT COUNT(*) FROM region_filtered_sales) AS processed_rows;

EXPORT SELECT * FROM execution_audit_log
TO "${output_dir}/audit_log_${environment}_${region}_${date}.csv"
TYPE CSV
OPTIONS { 
  "header": true
}; 